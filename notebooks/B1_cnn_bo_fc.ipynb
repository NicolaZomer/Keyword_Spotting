{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsT1FPnBguaJ"
      },
      "source": [
        "# Bayesian Optimization and Feature Comparison with CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lYQXwCmh402"
      },
      "source": [
        "## Get scripts from GitHub and install wget\n",
        "Only required when running on Colab. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V8fO0IpyMLd",
        "outputId": "caaac81e-c692-427f-aba7-f5d86affc2d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=cc58d71f805f044cda012c5e8997c471a85f31b9b61fd8d65942e89a7bced82b\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "! pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7ZaKB5zhwiz",
        "outputId": "261a8931-ff4b-4eba-e219-4bb41d6fbe17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-21 16:25:44--  https://raw.githubusercontent.com/NicolaZomer/Keyword_Spotting/main/utils/models_utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5727 (5.6K) [text/plain]\n",
            "Saving to: ‘models_utils.py’\n",
            "\n",
            "models_utils.py     100%[===================>]   5.59K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-21 16:25:44 (82.3 MB/s) - ‘models_utils.py’ saved [5727/5727]\n",
            "\n",
            "--2023-01-21 16:25:44--  https://raw.githubusercontent.com/NicolaZomer/Keyword_Spotting/main/utils/plot_utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2253 (2.2K) [text/plain]\n",
            "Saving to: ‘plot_utils.py’\n",
            "\n",
            "plot_utils.py       100%[===================>]   2.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-21 16:25:44 (46.1 MB/s) - ‘plot_utils.py’ saved [2253/2253]\n",
            "\n",
            "--2023-01-21 16:25:44--  https://raw.githubusercontent.com/NicolaZomer/Keyword_Spotting/main/utils/preprocessing_utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8952 (8.7K) [text/plain]\n",
            "Saving to: ‘preprocessing_utils.py’\n",
            "\n",
            "preprocessing_utils 100%[===================>]   8.74K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-21 16:25:45 (101 MB/s) - ‘preprocessing_utils.py’ saved [8952/8952]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget -nc https://raw.githubusercontent.com/NicolaZomer/Keyword_Spotting/main/utils/models_utils.py\n",
        "! wget -nc https://raw.githubusercontent.com/NicolaZomer/Keyword_Spotting/main/utils/plot_utils.py\n",
        "! wget -nc https://raw.githubusercontent.com/NicolaZomer/Keyword_Spotting/main/utils/preprocessing_utils.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFq83kJvyatv"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y_4uCFuXgucW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import requests\n",
        "import wget\n",
        "import inspect\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from IPython.display import display, Audio, Image\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score, log_loss, cohen_kappa_score\n",
        "\n",
        "from scipy.io import wavfile\n",
        "\n",
        "from models_utils import available_models, select_model\n",
        "import plot_utils \n",
        "\n",
        "plt.rcParams['font.size'] = '12'\n",
        "# %matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v58f7JtLicT4",
        "outputId": "533c75b0-c7bd-4688-de61-c47096e9a73e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-8b196a1e910a>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: True\n",
            "Version: 2.9.2\n"
          ]
        }
      ],
      "source": [
        "print(\"GPU Available:\", tf.test.is_gpu_available())\n",
        "print(\"Version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMYTM7mrgufm"
      },
      "source": [
        "To extract MFCC features from audio signals we use the Python library [python_speech_features](https://github.com/jameslyons/python_speech_features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83mmHptRgufv",
        "outputId": "c07ae372-fe82-4245-efa3-be093046521e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python_speech_features\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: python_speech_features\n",
            "  Building wheel for python_speech_features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python_speech_features: filename=python_speech_features-0.6-py3-none-any.whl size=5889 sha256=374704e1ee43340c42ab308ac3e173af9563ff97f10ae34e7ff90a50cfbdda3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/60/87/28af2605138deac93d162904df42b6fdda1dab9b8757c62aa3\n",
            "Successfully built python_speech_features\n",
            "Installing collected packages: python_speech_features\n",
            "Successfully installed python_speech_features-0.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting visualkeras\n",
            "  Downloading visualkeras-0.0.2-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from visualkeras) (7.1.2)\n",
            "Collecting aggdraw>=1.3.11\n",
            "  Downloading aggdraw-1.3.15-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (992 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m992.2/992.2 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.8/dist-packages (from visualkeras) (1.21.6)\n",
            "Installing collected packages: aggdraw, visualkeras\n",
            "Successfully installed aggdraw-1.3.15 visualkeras-0.0.2\n"
          ]
        }
      ],
      "source": [
        "# uncomment to install python_speech_features\n",
        "! pip install python_speech_features\n",
        "! pip install visualkeras\n",
        "\n",
        "from python_speech_features import logfbank, mfcc, delta\n",
        "import visualkeras\n",
        "\n",
        "import preprocessing_utils\n",
        "from preprocessing_utils import remove_file_starting_with"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N6hBU0Tgugj"
      },
      "source": [
        "To perform Discrete Wavelet Transform on audio signals we use the Python library [PyWavelets](https://github.com/PyWavelets/pywt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhiIcU5Xgugy",
        "outputId": "1e83193f-7752-4cd9-93b3-12d1becfe196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.8/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from PyWavelets) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "# uncomment to install PyWavelets\n",
        "! pip install PyWavelets\n",
        "\n",
        "from pywt import dwt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J6-132RguqS"
      },
      "source": [
        "## 1 - Data loading \n",
        "In this project we use the [Speech Commands dataset](https://www.tensorflow.org/datasets/catalog/speech_commands), which contains short (one-second long) audio clips of English commands, stored as audio files in the WAV format. More in detail, the version 0.02 of the dataset contains 105.829 utterances of 35 short words, by thousands of different people. It was released on April 11th 2018 under [Creative Commons BY 4.0 license](https://creativecommons.org/licenses/by/4.0/) and collected using crowdsourcing, through [AIY](https://aiyprojects.withgoogle.com/) by Google. Some of these words are \"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\" and \"go\".\n",
        "\n",
        "### 1.1 - Download data and create data folder\n",
        "We import both a smaller version of the Speech Commands dataset and the full version. The mini dataset can be used for testing and demo reasons, however the entire work will be focused only on the complete dataset (or a subset of it). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMEgF_1Oguqb",
        "outputId": "764bbdc2-b794-4f43-9034-50bc38cba7a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\n",
            "2428923189/2428923189 [==============================] - 64s 0us/step\n",
            "\n",
            "\n",
            "Working with the full dataset!\n"
          ]
        }
      ],
      "source": [
        "choose_dataset = 2 # 1 for mini, 2 for full\n",
        "download_also_mini = False\n",
        "\n",
        "DATASET_PATH_mini = 'data/mini_speech_commands'\n",
        "DATASET_PATH_full = 'data/full_speech_commands'\n",
        "\n",
        "data_dir_mini = pathlib.Path(DATASET_PATH_mini)\n",
        "if not data_dir_mini.exists() and download_also_mini:\n",
        "  tf.keras.utils.get_file(\n",
        "      'mini_speech_commands.zip',\n",
        "      origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n",
        "      extract=True,\n",
        "      cache_dir='.', cache_subdir='data')\n",
        "  print('\\n')\n",
        "  \n",
        "data_dir_full = pathlib.Path(DATASET_PATH_full)\n",
        "if not data_dir_full.exists():\n",
        "  tf.keras.utils.get_file(\n",
        "      'full_speech_commands.zip',\n",
        "      origin=\"http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\",\n",
        "      extract=True,\n",
        "      cache_dir='.', cache_subdir='data/full_speech_commands')\n",
        "  print('\\n')\n",
        "  \n",
        "if choose_dataset==1:\n",
        "  data_dir = data_dir_mini\n",
        "  data_path = DATASET_PATH_mini\n",
        "  print('Working with the mini dataset!')\n",
        "elif choose_dataset==2:\n",
        "  data_dir = data_dir_full\n",
        "  data_path = DATASET_PATH_full\n",
        "  print('Working with the full dataset!')\n",
        "else:\n",
        "  print(\"Error, 'choose_dataset' must be 1 or 2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TajS9BZPgurM"
      },
      "source": [
        "### 1.2 - Dataset organization\n",
        "The audio files are organized into folders based on the word they contain. For more details see \\[[Warden18](https://arxiv.org/abs/1804.03209)\\].\n",
        "\n",
        "**Mini dataset** <br>\n",
        "The dataset's audio clips are stored in 8 folders corresponding to each speech command: `down`, `go`, `left`, `no`, `right`, `stop`, `up`, `yes`, and `stop`. \n",
        "\n",
        "**Full dataset** <br>\n",
        "The dataset's audio clips are stored in 35 folders corresponding to each speech command: <br>\n",
        "`backward`, `bed`, `bird`, `cat`, `dog`, `down`, `eight`, `five`, `follow`, `forward`, `four`, `go`, `happy`, `house`, `learn`, `left`, `marvin`, `nine`, `no`, `off`, `on`, `one`, `right`, `seven`, `sheila`, `six`, `stop`, `three`, `tree`, `two`, `up`, `visual`, `wow`, `yes`, `zero`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE9p410cgur8",
        "outputId": "6db0a8f4-5fc0-4537-a466-5ef23c02b4c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Commands: ['backward', 'bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'follow', 'forward', 'four', 'go', 'happy', 'house', 'learn', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'visual', 'wow', 'yes', 'zero']\n",
            "\n",
            "Number of commands: 35\n"
          ]
        }
      ],
      "source": [
        "commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
        "\n",
        "if choose_dataset==1:\n",
        "  mask = commands != 'README.md'\n",
        "\n",
        "elif choose_dataset==2:\n",
        "  mask = (\n",
        "      np.array(commands != 'README.md')                 &\n",
        "      np.array(commands != 'LICENSE')                   &\n",
        "      np.array(commands != '.DS_Store')                 &\n",
        "      np.array(commands != 'training_list.txt')         &  \n",
        "      np.array(commands != 'validation_list.txt')       &  \n",
        "      np.array(commands != 'testing_list.txt')          &  \n",
        "      np.array(commands != 'full_speech_commands.zip')  &\n",
        "      np.array(commands != '_background_noise_')        \n",
        "  )\n",
        "  \n",
        "commands = sorted(commands[mask])\n",
        "print('Commands:', commands)\n",
        "\n",
        "print('\\nNumber of commands: %i' %len(commands))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_HQ4GIRguvw"
      },
      "source": [
        "### 1.3 - Processing of the original audio files \n",
        "The original audio files were captured in a variety of formats and then converted to .WAV file at a 16000 sample rate. The audio was then trimmed to a one second length to align most utterances, using the [extract_loudest_section](https://github.com/petewarden/extract_loudest_section) tool. The audio files were then screened for silence or incorrect words, and arranged into folders by label.\n",
        "\n",
        "### 1.4 - Training, testing and validation sets\n",
        "The text files `validation_list.txt` and `testing_list.txt` available in the [Speech Commands dataset](https://www.tensorflow.org/datasets/catalog/speech_commands) contain the paths to all the files in each set, with each path on a new line. Any files that aren't in either of these lists can be considered to be part of the training set. The validation and test set sizes thus obtained are approximatly 10% of the size of the complete set. For more information on how the partition is made, see the README.md file of the dataset. \n",
        "\n",
        "The following code performs these operations:\n",
        "- Load the reference validation and testing files as separated Pandas dataframe objects. \n",
        "- Store the path of all audio files in a dictionary. \n",
        "- Create the reference file for training data, by storing in a Pandas dataframe object the paths of all files that aren't in the validation or testing list. If it has been already created, we simply import it as we did for the reference validation and testing files. \n",
        "\n",
        "To each file we associate the corresponding label (i.e. the name of the folder it is in), so that we get a proper labeling for each file to be used with our loss function. Of course, we still need to load the actual data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fygRaSrguv0",
        "outputId": "efc4733f-6399-45f1-cf61-f5f354517c0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 105829 audio files in the dataset\n",
            "File downloaded from GitHub\n"
          ]
        }
      ],
      "source": [
        "training_list_path = data_path + \"/training_list.txt\"\n",
        "\n",
        "reference_df_val = pd.read_csv(data_path+\"/validation_list.txt\", sep=\"/\", header=None, names=['label', 'file'])\n",
        "reference_df_test = pd.read_csv(data_path+\"/testing_list.txt\", sep=\"/\", header=None, names=['label', 'file'])\n",
        "\n",
        "# all audio files\n",
        "all_files = {}\n",
        "for command in commands:\n",
        "    all_files[command] = os.listdir(data_path+'/'+command)\n",
        "    \n",
        "num_files = 0\n",
        "for x_ in all_files.values():\n",
        "    num_files += len(x_)\n",
        "        \n",
        "print('There are %i audio files in the dataset' %num_files)\n",
        "\n",
        "# reference file for training set\n",
        "# if already exists import it\n",
        "if pathlib.Path(training_list_path).exists(): \n",
        "    reference_df_train =  pd.read_csv(data_path+\"/training_list.txt\", sep=\"/\", header=None, names=['label', 'file'])\n",
        "    \n",
        "# else search if it can be dowloaded\n",
        "else: \n",
        "  training_list_url = 'https://raw.githubusercontent.com/NicolaZomer/Keyword_Spotting/main/training_list.txt'\n",
        "  response = requests.get(training_list_url)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "      wget.download(training_list_url, out=str(data_path))\n",
        "      print('File downloaded from GitHub')\n",
        "\n",
        "      reference_df_train =  pd.read_csv(data_path+\"/training_list.txt\", sep=\"/\", header=None, names=['label', 'file'])\n",
        "\n",
        "  else: # create it and store the dataframe as a .txt file; creating the pd object can take some time\n",
        "      print('File not found, error '+str(response.status_code))\n",
        "\n",
        "      reference_df_train = pd.DataFrame(columns=['label', 'file'])\n",
        "      for i, command in enumerate(commands):\n",
        "          print(\"Processing command '%s', %i commands missing...\" %(command, len(commands)-i-1))\n",
        "          for file in all_files[command]:\n",
        "              if file in reference_df_val['file'].values:\n",
        "                  continue\n",
        "              if file in reference_df_test['file'].values:\n",
        "                  continue\n",
        "\n",
        "              reference_df_train.loc[len(reference_df_train)] = [command, file]\n",
        "\n",
        "      print('Done!')\n",
        "      print('\\n')\n",
        "\n",
        "      # store reference_df_train in .txt file\n",
        "      reference_df_train.to_csv(data_path+'/training_list.txt', header=None, index=None, sep='/', mode='a')\n",
        "\n",
        "# print the result\n",
        "# print('----------------------------')\n",
        "# print('TRAINING FILES:')\n",
        "# print(reference_df_train)\n",
        "# print('----------------------------')\n",
        "# print('VALIDATION FILES:')\n",
        "# print(reference_df_val)\n",
        "# print('----------------------------')\n",
        "# print('TESTING FILES:')\n",
        "# print(reference_df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2naK4mEeguv5"
      },
      "source": [
        "Encode target labels with value between 0 and n_commands-1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tyTfKJQbguv6"
      },
      "outputs": [],
      "source": [
        "label_to_class = {commands[i]:i for i in range(len(commands))}\n",
        "# label_to_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9bEaJKJkguv7"
      },
      "outputs": [],
      "source": [
        "class_to_label = {i:commands[i] for i in range(len(commands))}\n",
        "# class_to_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vgwIDfSguv8",
        "outputId": "7c8c9ed3-8173-4523-c436-5a3cd71b3e68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING FILES:\n",
            "          label                   file  class\n",
            "0      backward  0165e0e8_nohash_0.wav      0\n",
            "1      backward  017c4098_nohash_0.wav      0\n",
            "2      backward  017c4098_nohash_1.wav      0\n",
            "3      backward  017c4098_nohash_2.wav      0\n",
            "4      backward  017c4098_nohash_3.wav      0\n",
            "...         ...                    ...    ...\n",
            "84838      zero  ffd2ba2f_nohash_1.wav     34\n",
            "84839      zero  ffd2ba2f_nohash_2.wav     34\n",
            "84840      zero  ffd2ba2f_nohash_3.wav     34\n",
            "84841      zero  ffd2ba2f_nohash_4.wav     34\n",
            "84842      zero  fffcabd1_nohash_0.wav     34\n",
            "\n",
            "[84843 rows x 3 columns]\n",
            "----------------------------\n",
            "VALIDATION FILES:\n",
            "      label                   file  class\n",
            "0     right  a69b9b3e_nohash_0.wav     22\n",
            "1     right  439c84f4_nohash_1.wav     22\n",
            "2     right  409c962a_nohash_1.wav     22\n",
            "3     right  dbaf8fc6_nohash_2.wav     22\n",
            "4     right  a6d586b7_nohash_1.wav     22\n",
            "...     ...                    ...    ...\n",
            "9976   four  d107dc42_nohash_0.wav     10\n",
            "9977   four  ad63d93c_nohash_0.wav     10\n",
            "9978   four  d3831f6a_nohash_1.wav     10\n",
            "9979   four  3c4aa5ef_nohash_3.wav     10\n",
            "9980   four  c6389ab0_nohash_0.wav     10\n",
            "\n",
            "[9981 rows x 3 columns]\n",
            "----------------------------\n",
            "TESTING FILES:\n",
            "       label                   file  class\n",
            "0      right  bb05582b_nohash_3.wav     22\n",
            "1      right  97f4c236_nohash_2.wav     22\n",
            "2      right  f2e59fea_nohash_3.wav     22\n",
            "3      right  fdb5155e_nohash_2.wav     22\n",
            "4      right  dc75148d_nohash_0.wav     22\n",
            "...      ...                    ...    ...\n",
            "11000   four  189cbabe_nohash_2.wav     10\n",
            "11001   four  8fe67225_nohash_3.wav     10\n",
            "11002   four  c9e251d2_nohash_1.wav     10\n",
            "11003   four  0c40e715_nohash_0.wav     10\n",
            "11004   four  8769c34c_nohash_3.wav     10\n",
            "\n",
            "[11005 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "reference_df_train['class'] = reference_df_train['label'].map(label_to_class)\n",
        "reference_df_val['class']   = reference_df_val['label'].map(label_to_class)\n",
        "reference_df_test['class']  = reference_df_test['label'].map(label_to_class)\n",
        "\n",
        "# print the result\n",
        "print('TRAINING FILES:')\n",
        "print(reference_df_train)\n",
        "print('----------------------------')\n",
        "print('VALIDATION FILES:')\n",
        "print(reference_df_val)\n",
        "print('----------------------------')\n",
        "print('TESTING FILES:')\n",
        "print(reference_df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdOpKmpwguwi",
        "outputId": "f3964d31-4f4e-4e76-be63-5337188c8c37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING SET\n",
            "\tnumber of audio files: 84843\n",
            "\tpercentage of audio files: 80.17%\n",
            "VALIDATION SET\n",
            "\tnumber of audio files: 9981\n",
            "\tpercentage of audio files: 9.43%\n",
            "TEST SET\n",
            "\tnumber of audio files: 11005\n",
            "\tpercentage of audio files: 10.40%\n"
          ]
        }
      ],
      "source": [
        "print('TRAINING SET')\n",
        "print('\\tnumber of audio files: %i' %len(reference_df_train))\n",
        "print('\\tpercentage of audio files: %.2f%%' %(len(reference_df_train)/num_files*100))\n",
        "\n",
        "print('VALIDATION SET')\n",
        "print('\\tnumber of audio files: %i' %len(reference_df_val))\n",
        "print('\\tpercentage of audio files: %.2f%%' %(len(reference_df_val)/num_files*100))\n",
        "\n",
        "print('TEST SET')\n",
        "print('\\tnumber of audio files: %i' %len(reference_df_test))\n",
        "print('\\tpercentage of audio files: %.2f%%' %(len(reference_df_test)/num_files*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OntieQwayQN"
      },
      "source": [
        "### 1.4 Noise loading \n",
        "We load here the available noisy audio signals and we defined the object `noise_dict`, which is required by the function `load_and_preprocessing_data` (see next section)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_Mm2LkLaxUT",
        "outputId": "4511be22-1bf7-4fa9-afec-0851eb658393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/preprocessing_utils.py:69: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
            "  _, data = wavfile.read(file_path)\n"
          ]
        }
      ],
      "source": [
        "noise_path = '_background_noise_'\n",
        "\n",
        "# load all noises \n",
        "noise_1 = preprocessing_utils.load_data('doing_the_dishes.wav', noise_path)\n",
        "noise_2 = preprocessing_utils.load_data('dude_miaowing.wav', noise_path)\n",
        "noise_3 = preprocessing_utils.load_data('exercise_bike.wav', noise_path)\n",
        "noise_4 = preprocessing_utils.load_data('pink_noise.wav', noise_path)\n",
        "noise_5 = preprocessing_utils.load_data('running_tap.wav', noise_path)\n",
        "noise_6 = preprocessing_utils.load_data('white_noise.wav', noise_path)\n",
        "\n",
        "noise_dict = {\n",
        "    '1': noise_1, \n",
        "    '2': noise_2, \n",
        "    '3': noise_3, \n",
        "    '4': noise_4, \n",
        "    '5': noise_5, \n",
        "    '6': noise_6\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af53Vbe4gu07"
      },
      "source": [
        "## 2 - Data Loading using the Dataset API\n",
        "As the dataset is quite large (>5GiB), there is the risk that it will not entirely fit in the memory, plus the preprocessing pipeline would be computationally intensive. For these reasons, we want to implement a proper and optimized data-loading pipeline, as reading the data can be the main bottleneck of the entire training process. This can be done by exploit the [Tensorflow Dataset API](https://www.tensorflow.org/guide/datasets).\n",
        "\n",
        "The main goal of this phase is to create a `tf.data.Dataset` object to efficiently load and preprocess your data. \n",
        "\n",
        "## 2.1 Loading and preprocessing\n",
        "First, to load and preprocess the data, we use the function `load_and_preprocess_data`, defined in the file `preprocessing_utils.py`. This function puts together all loading and preprocessing methods that can be explored in the notebook `B1_data_analysis_and_preprocessing_inspection.ipynb`. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPDcrdmCY17R",
        "outputId": "eb09ff12-247a-4239-c049-85117dfa5cf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def load_and_preprocess_data(file_name, file_label, data_path_=data_path, apply_background_noise=False, noise_dict=None, noise_reduction=0.5, features=1, resize=False):\n",
            "    '''\n",
            "    features:\n",
            "    - 1 for MFCC features (default), delta_order=2\n",
            "    - 2 for log Mel-filterbank energy features\n",
            "    - 3 for spectrogram\n",
            "    - 4 for Discrete Wavelet Transform + MFCC features\n",
            "    - 5 for MFCC features, delta_order=0\n",
            "    '''\n",
            "    \n",
            "    # load data\n",
            "    data = load_data(file_name, file_label, data_path_=data_path_)\n",
            "    \n",
            "    # padding/trimming\n",
            "    data = padding_trimming(data)\n",
            "    \n",
            "    # add background noise\n",
            "    if apply_background_noise:\n",
            "        data = background_noise(data, noise_dict=noise_dict, noise_reduction=noise_reduction)\n",
            "\n",
            "    # extract features\n",
            "    if features == 1:\n",
            "        data_features = get_mfcc(data)\n",
            "    \n",
            "    elif features == 2:\n",
            "        data_features = get_logfbank(data)\n",
            "\n",
            "    elif features == 3:\n",
            "        data_features = get_spectrogram(data)\n",
            "\n",
            "    elif features == 4:\n",
            "        data, _ = dwt(data=data, wavelet='db1', mode='sym')\n",
            "        data_features = get_mfcc(data)\n",
            "        \n",
            "    elif features == 5:\n",
            "        data_features = get_mfcc(data, delta_order=0)\n",
            "        \n",
            "    elif features == 6:\n",
            "        data_features = get_logfbank(data, winlen=32, winstep=15.5, nfilt=64)\n",
            "        \n",
            "    else:\n",
            "        data_features = data\n",
            "    \n",
            "    # resize feature vector\n",
            "    if resize:\n",
            "        data_features = np.resize(data_features, (50, 50))\n",
            "        \n",
            "    # TensorFlow takes as input 32-bit floating point data\n",
            "    return data_features.astype(np.float32)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(inspect.getsource(preprocessing_utils.load_and_preprocess_data))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fIv5VEdgu1a"
      },
      "source": [
        "### 2.1 - Dataset definition\n",
        "We now define the `create_dataset` function, which initializes a `tf.data.Dataset` object and properly maps all the required processing. More details on this procedure can be found [here](https://www.tensorflow.org/guide/performance/datasets), along with additional tips and tricks for performance optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IpL9t-wfcgSu"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_noisedict_passed(file_name, file_label, data_path_=data_path, apply_background_noise=False, noise_reduction=0.5, features=1):\n",
        "  return preprocessing_utils.load_and_preprocess_data(\n",
        "        file_name, file_label, data_path_=data_path_, \n",
        "        apply_background_noise=False, noise_dict=noise_dict, noise_reduction=noise_reduction, \n",
        "        features=features, resize=False\n",
        "      )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lRoZ6waNgu1a"
      },
      "outputs": [],
      "source": [
        "def create_dataset(df, data_path_=data_path, apply_background_noise=False, features=2, cache_file=None, shuffle=True, batch_size=32, noise_reduction=0.5):\n",
        "\n",
        "    # Convert DataFrame to lists\n",
        "    file_names = df['file'].tolist()\n",
        "    file_labels = df['class'].tolist()\n",
        "\n",
        "    # Create a Dataset object\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((file_names, file_labels))\n",
        "\n",
        "    # Map the load_and_preprocess_data function\n",
        "    def numpy_func(file_name, file_label):\n",
        "        return tf.numpy_function(load_and_preprocess_noisedict_passed, inp=[file_name, file_label, data_path_, apply_background_noise, noise_reduction, features], Tout=tf.float32), file_label\n",
        "    dataset = dataset.map(numpy_func, num_parallel_calls=os.cpu_count())\n",
        "\n",
        "    # Cache\n",
        "    if cache_file:\n",
        "        dataset = dataset.cache(filename=cache_file)\n",
        "\n",
        "    # Shuffle\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(df))\n",
        "\n",
        "    # Repeat the dataset indefinitely\n",
        "    dataset = dataset.repeat()\n",
        "\n",
        "    # Batch\n",
        "    dataset = dataset.batch(batch_size=batch_size)\n",
        "\n",
        "    # Prefetch\n",
        "    dataset = dataset.prefetch(buffer_size=1)\n",
        "\n",
        "    # Steps\n",
        "    steps = int(np.ceil(len(df) / batch_size))\n",
        "\n",
        "    return dataset, steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7wcCw0Kgu1b"
      },
      "source": [
        "### 2.2 - Dataset initialization\n",
        "Finally, we define the training, validation and testing dataset, applying the above function to each of the corresponding reference dataframes. We also evaluate the number of steps (*train_steps*, *val_steps* and *test_steps*) required to load and process the entire dataset (num. of samples / batch_size).\n",
        "\n",
        "We perform the Bayesian Optimization using the log Mel-filterbank energies, as from some preliminary tests we have seen that they could lead to best performances. For this reason we set `features_to_extract=2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "i2c5zxUVgu1b"
      },
      "outputs": [],
      "source": [
        "apply_bn = True\n",
        "noise_red = 0.5\n",
        "features_to_extract = 2 # for log Mel-filterbank energy features\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset, train_steps = create_dataset(\n",
        "    reference_df_train, \n",
        "    apply_background_noise=apply_bn,\n",
        "    noise_reduction=noise_red,\n",
        "    features=features_to_extract,\n",
        "    cache_file='train_cache',\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_dataset, val_steps = create_dataset(\n",
        "    reference_df_val,\n",
        "    apply_background_noise=apply_bn,\n",
        "    noise_reduction=noise_red,\n",
        "    features=features_to_extract,\n",
        "    cache_file='val_cache',\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# important, shuffle=False and do not apply bn in the test set\n",
        "apply_bn=False\n",
        "test_dataset, test_steps = create_dataset(\n",
        "    reference_df_test,\n",
        "    apply_background_noise=apply_bn, \n",
        "    features=features_to_extract,\n",
        "    cache_file='test_cache',\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAzYaBq6avvO"
      },
      "source": [
        "# Bayesian Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dp116A5gu1c"
      },
      "source": [
        "## 3 - BO, introduction\n",
        "Bayesian optimization is a strategy to find the optimum of a black-box function, whose analytic form is not known and which is expensive to evaluate. The optimization is achieved through a sequential data\n",
        "driven scenario, where the goal is to improve the guess of the optimum while being data efficient in terms of how many queries we ask of the black-box. In this case we apply it to find the CNN model parameter values that lead to the best accuracy.\n",
        "\n",
        "For more information, refer to the following references: \n",
        "- [Bayesian optimization with skopt — scikit-optimize 0.8.1 documentation](https://scikit-optimize.github.io/stable/auto_examples/bayesian-optimization.html)\n",
        "- [Bayesian Optimisation: Gaussian processes & Beyond — Haitham Bou Ammar (LinkedIn)](https://www.linkedin.com/posts/haitham-bou-ammar-a723a932_long-bayesian-optimisation-talk-from-simple-activity-6989891577967968256-b6DC?utm_source=share&utm_medium=member_desktop)\n",
        "\n",
        "### 3.0 - Import for BO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IavVFHif1vRL",
        "outputId": "e9d63b26-61eb-4ab3-9857-f07b7cbc9bfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/100.3 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q scikit-optimize\n",
        "\n",
        "from skopt.space import Real, Integer\n",
        "from skopt.utils import use_named_args\n",
        "from skopt.plots import plot_convergence \n",
        "\n",
        "from skopt import gp_minimize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_ig3uhw1oi7"
      },
      "source": [
        "### 3.1 - Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bvPRWpCRgu1f"
      },
      "outputs": [],
      "source": [
        "features_to_input = { # input shapes\n",
        "    1 : (99, 13),     # MFCC features with delta\n",
        "    2 : (99, 40),     # log Mel-filterbank energy features\n",
        "    3 : (98, 257),    # spectrogram\n",
        "    4 : (49, 39),     # Discrete Wavelet Transform + MFCC features\n",
        "    5 : (99, 13)      # MFCC features no delta\n",
        "}\n",
        "\n",
        "input_shape = features_to_input[features_to_extract]\n",
        "\n",
        "def custom_cnn_simple(\n",
        "    input_shape, \n",
        "    nf_sp_1, nf_sp_2, nk_sp_l, nk_sp_r, mp_sp, dp_sp, \n",
        "    nf_tp_1, nf_tp_2, nk_tp_l, nk_tp_r, mp_tp_1, mp_tp_2, dp_tp, \n",
        "    dp_fc, lr\n",
        "    ):\n",
        "    '''\n",
        "      4 cnn blocks, 2x (2, 2) pooling, 2x pooling in time\n",
        "    '''\n",
        "\n",
        "    model = tf.keras.models.Sequential(name='custom_cnn')\n",
        "\n",
        "    model.add(tf.keras.layers.Reshape(input_shape=input_shape, target_shape=(input_shape[0], input_shape[1], 1)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    filters_pool = [nf_sp_1, nf_sp_2]\n",
        "\n",
        "    for num_filters in filters_pool:\n",
        "\n",
        "      model.add(tf.keras.layers.Conv2D(num_filters, kernel_size=(nk_sp_l, nk_sp_r), padding='same'))\n",
        "      model.add(tf.keras.layers.BatchNormalization())\n",
        "      model.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "      model.add(tf.keras.layers.MaxPooling2D(pool_size=(mp_sp, mp_sp)))\n",
        "      model.add(tf.keras.layers.Dropout(dp_sp))\n",
        "\n",
        "    filters_pool_in_time = [nf_tp_1, nf_tp_2]\n",
        "\n",
        "    for p, num_filters in zip([mp_tp_1, mp_tp_2], filters_pool_in_time):\n",
        "\n",
        "      model.add(tf.keras.layers.Conv2D(num_filters, kernel_size=(nk_tp_l, nk_tp_r), padding='same'))\n",
        "      model.add(tf.keras.layers.BatchNormalization())\n",
        "      model.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "      model.add(tf.keras.layers.MaxPooling2D(pool_size=(p, 1)))\n",
        "      model.add(tf.keras.layers.Dropout(dp_tp))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dropout(dp_fc))\n",
        "    model.add(tf.keras.layers.Dense(256))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation('relu'))\n",
        "    model.add(tf.keras.layers.Dense(35, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy', \n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "model_name = 'custom_cnn_simple'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXtyU_GnWTzg"
      },
      "source": [
        "### 3.2 - Search space dimensions and objective function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "079jwj07ndiU"
      },
      "outputs": [],
      "source": [
        "search_space  = [\n",
        "    Integer(2, 128, name='nf_sp_1'),\n",
        "    Integer(2, 128, name='nf_sp_2'),\n",
        "    Integer(2, 8, name='nk_sp_l'),\n",
        "    Integer(2, 8, name='nk_sp_r'),\n",
        "    Integer(1, 3, name='mp_sp'),\n",
        "    Real(0.1, 0.5, name='dp_sp'),\n",
        "\n",
        "    Integer(8, 256, name='nf_tp_1'),\n",
        "    Integer(8, 256, name='nf_tp_2'),\n",
        "    Integer(2, 8, name='nk_tp_l'),\n",
        "    Integer(2, 8, name='nk_tp_r'),\n",
        "    Integer(1, 3, name='mp_tp_1'),\n",
        "    Integer(1, 3, name='mp_tp_2'),\n",
        "    Real(0.1, 0.5, name='dp_tp'),\n",
        "\n",
        "    Real(0.1, 0.5, name='dp_fc'),\n",
        "    Real(1e-6, 1e-2, 'log-uniform', name='lr')\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7jlOmoCM61B2"
      },
      "outputs": [],
      "source": [
        "@use_named_args(search_space)\n",
        "def objective_f(nf_sp_1, nf_sp_2, nk_sp_l, nk_sp_r, mp_sp, dp_sp, \n",
        "      nf_tp_1, nf_tp_2, nk_tp_l, nk_tp_r, mp_tp_1, mp_tp_2, dp_tp, \n",
        "      dp_fc, lr):\n",
        "    model = custom_cnn_simple(\n",
        "      input_shape, \n",
        "      nf_sp_1, nf_sp_2, nk_sp_l, nk_sp_r, mp_sp, dp_sp, \n",
        "      nf_tp_1, nf_tp_2, nk_tp_l, nk_tp_r, mp_tp_1, mp_tp_2, dp_tp, \n",
        "      dp_fc, lr\n",
        "    )\n",
        "    \n",
        "    num_epochs = 20\n",
        "\n",
        "    early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "    reduce_LR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1)\n",
        "    \n",
        "    history = model.fit(\n",
        "                train_dataset,\n",
        "                epochs=num_epochs,\n",
        "                steps_per_epoch=train_steps,\n",
        "                validation_data=val_dataset,\n",
        "                validation_steps=val_steps,\n",
        "                callbacks=[early_stop_callback, reduce_LR], \n",
        "                verbose=0\n",
        "                )\n",
        "    \n",
        "    # get last epoch accuracy and print is\n",
        "    accuracy = history.history['val_sparse_categorical_accuracy'][-1]\n",
        "    \n",
        "    print(\"\\n\\nAccuracy: {0:.2%}\\n\\n\".format(accuracy))\n",
        "\n",
        "    # clean memory: delete model and clean session \n",
        "    del model\n",
        "    \n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    return -accuracy # minus because it returns what we want to minimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGJ5IAK-7kk6",
        "outputId": "75ea58ef-9269-4d6b-82cf-8fd2e2f3c70d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration No: 1 started. Evaluating function at random point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Accuracy: 91.18%\n",
            "\n",
            "\n",
            "Iteration No: 1 ended. Evaluation done at random point.\n",
            "Time taken: 5723.5120\n",
            "Function value obtained: -0.9118\n",
            "Current minimum: -0.9118\n",
            "Iteration No: 2 started. Evaluating function at random point.\n",
            "\n",
            "\n",
            "Accuracy: 67.21%\n",
            "\n",
            "\n",
            "Iteration No: 2 ended. Evaluation done at random point.\n",
            "Time taken: 743.0302\n",
            "Function value obtained: -0.6721\n",
            "Current minimum: -0.9118\n",
            "Iteration No: 3 started. Evaluating function at random point.\n",
            "\n",
            "\n",
            "Accuracy: 80.86%\n",
            "\n",
            "\n",
            "Iteration No: 3 ended. Evaluation done at random point.\n",
            "Time taken: 923.2033\n",
            "Function value obtained: -0.8086\n",
            "Current minimum: -0.9118\n",
            "Iteration No: 4 started. Evaluating function at random point.\n",
            "\n",
            "\n",
            "Accuracy: 87.76%\n",
            "\n",
            "\n",
            "Iteration No: 4 ended. Evaluation done at random point.\n",
            "Time taken: 983.1694\n",
            "Function value obtained: -0.8776\n",
            "Current minimum: -0.9118\n",
            "Iteration No: 5 started. Evaluating function at random point.\n",
            "\n",
            "\n",
            "Accuracy: 67.22%\n",
            "\n",
            "\n",
            "Iteration No: 5 ended. Evaluation done at random point.\n",
            "Time taken: 878.4694\n",
            "Function value obtained: -0.6722\n",
            "Current minimum: -0.9118\n",
            "Iteration No: 6 started. Evaluating function at random point.\n",
            "\n",
            "\n",
            "Accuracy: 47.70%\n",
            "\n",
            "\n",
            "Iteration No: 6 ended. Evaluation done at random point.\n",
            "Time taken: 575.3358\n",
            "Function value obtained: -0.4770\n",
            "Current minimum: -0.9118\n",
            "Iteration No: 7 started. Evaluating function at random point.\n",
            "\n",
            "\n",
            "Accuracy: 14.28%\n",
            "\n",
            "\n",
            "Iteration No: 7 ended. Evaluation done at random point.\n",
            "Time taken: 623.0400\n",
            "Function value obtained: -0.1428\n",
            "Current minimum: -0.9118\n",
            "Iteration No: 8 started. Evaluating function at random point.\n",
            "\n",
            "\n",
            "Accuracy: 85.20%\n",
            "\n",
            "\n",
            "Iteration No: 8 ended. Evaluation done at random point.\n",
            "Time taken: 863.0069\n",
            "Function value obtained: -0.8520\n",
            "Current minimum: -0.9118\n",
            "Iteration No: 9 started. Evaluating function at random point.\n",
            "\n",
            "\n",
            "Accuracy: 90.97%\n",
            "\n",
            "\n",
            "Iteration No: 9 ended. Evaluation done at random point.\n",
            "Time taken: 5784.6899\n",
            "Function value obtained: -0.9097\n",
            "Current minimum: -0.9118\n",
            "Iteration No: 10 started. Evaluating function at random point.\n",
            "\n",
            "\n",
            "Accuracy: 87.36%\n",
            "\n",
            "\n",
            "Iteration No: 10 ended. Evaluation done at random point.\n",
            "Time taken: 404.5852\n",
            "Function value obtained: -0.8736\n",
            "Current minimum: -0.9118\n",
            "Iteration No: 11 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.05108803533949e-06.\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 4.05108812628896e-07.\n",
            "\n",
            "\n",
            "Accuracy: 91.49%\n",
            "\n",
            "\n",
            "Iteration No: 11 ended. Search finished for the next optimal point.\n",
            "Time taken: 6023.5126\n",
            "Function value obtained: -0.9149\n",
            "Current minimum: -0.9149\n",
            "Iteration No: 12 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Accuracy: 77.46%\n",
            "\n",
            "\n",
            "Iteration No: 12 ended. Search finished for the next optimal point.\n",
            "Time taken: 904.3447\n",
            "Function value obtained: -0.7746\n",
            "Current minimum: -0.9149\n",
            "Iteration No: 13 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Accuracy: 79.45%\n",
            "\n",
            "\n",
            "Iteration No: 13 ended. Search finished for the next optimal point.\n",
            "Time taken: 803.6716\n",
            "Function value obtained: -0.7945\n",
            "Current minimum: -0.9149\n",
            "Iteration No: 14 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Accuracy: 83.74%\n",
            "\n",
            "\n",
            "Iteration No: 14 ended. Search finished for the next optimal point.\n",
            "Time taken: 1044.0244\n",
            "Function value obtained: -0.8374\n",
            "Current minimum: -0.9149\n",
            "Iteration No: 15 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.9234515750431456e-06.\n",
            "\n",
            "\n",
            "Accuracy: 89.88%\n",
            "\n",
            "\n",
            "Iteration No: 15 ended. Search finished for the next optimal point.\n",
            "Time taken: 6143.5191\n",
            "Function value obtained: -0.8988\n",
            "Current minimum: -0.9149\n",
            "Iteration No: 16 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.6177868019440213e-06.\n",
            "\n",
            "\n",
            "Accuracy: 31.74%\n",
            "\n",
            "\n",
            "Iteration No: 16 ended. Search finished for the next optimal point.\n",
            "Time taken: 383.4020\n",
            "Function value obtained: -0.3174\n",
            "Current minimum: -0.9149\n",
            "Iteration No: 17 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 6.540543108712882e-06.\n",
            "\n",
            "\n",
            "Accuracy: 90.78%\n",
            "\n",
            "\n",
            "Iteration No: 17 ended. Search finished for the next optimal point.\n",
            "Time taken: 743.5392\n",
            "Function value obtained: -0.9078\n",
            "Current minimum: -0.9149\n",
            "Iteration No: 18 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00022847854997962714.\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 2.2847854415886105e-05.\n",
            "\n",
            "\n",
            "Accuracy: 91.71%\n",
            "\n",
            "\n",
            "Iteration No: 18 ended. Search finished for the next optimal point.\n",
            "Time taken: 3863.5165\n",
            "Function value obtained: -0.9171\n",
            "Current minimum: -0.9171\n",
            "Iteration No: 19 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.055695658782497e-05.\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 2.055695586022921e-06.\n",
            "\n",
            "\n",
            "Accuracy: 91.61%\n",
            "\n",
            "\n",
            "Iteration No: 19 ended. Search finished for the next optimal point.\n",
            "Time taken: 4584.9453\n",
            "Function value obtained: -0.9161\n",
            "Current minimum: -0.9171\n",
            "Iteration No: 20 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009554545395076275.\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 9.554545395076276e-05.\n",
            "\n",
            "\n",
            "Accuracy: 89.25%\n",
            "\n",
            "\n",
            "Iteration No: 20 ended. Search finished for the next optimal point.\n",
            "Time taken: 429.8047\n",
            "Function value obtained: -0.8925\n",
            "Current minimum: -0.9171\n",
            "Iteration No: 21 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 3.523117047734559e-05.\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 3.5231169022154063e-06.\n",
            "\n",
            "\n",
            "Accuracy: 90.11%\n",
            "\n",
            "\n",
            "Iteration No: 21 ended. Search finished for the next optimal point.\n",
            "Time taken: 3323.4001\n",
            "Function value obtained: -0.9011\n",
            "Current minimum: -0.9171\n",
            "Iteration No: 22 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 8.384155808016659e-06.\n",
            "\n",
            "\n",
            "Accuracy: 92.48%\n",
            "\n",
            "\n",
            "Iteration No: 22 ended. Search finished for the next optimal point.\n",
            "Time taken: 5363.9511\n",
            "Function value obtained: -0.9248\n",
            "Current minimum: -0.9248\n",
            "Iteration No: 23 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0007373829372227192.\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 7.37382913939655e-05.\n",
            "\n",
            "\n",
            "Accuracy: 93.21%\n",
            "\n",
            "\n",
            "Iteration No: 23 ended. Search finished for the next optimal point.\n",
            "Time taken: 922.0916\n",
            "Function value obtained: -0.9321\n",
            "Current minimum: -0.9321\n",
            "Iteration No: 24 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 2.1247580298222603e-05.\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 2.1247580662020484e-06.\n",
            "\n",
            "\n",
            "Accuracy: 92.74%\n",
            "\n",
            "\n",
            "Iteration No: 24 ended. Search finished for the next optimal point.\n",
            "Time taken: 5022.9299\n",
            "Function value obtained: -0.9274\n",
            "Current minimum: -0.9321\n",
            "Iteration No: 25 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Accuracy: 85.61%\n",
            "\n",
            "\n",
            "Iteration No: 25 ended. Search finished for the next optimal point.\n",
            "Time taken: 1043.6623\n",
            "Function value obtained: -0.8561\n",
            "Current minimum: -0.9321\n",
            "Iteration No: 26 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0007281574420630933.\n",
            "\n",
            "\n",
            "Accuracy: 92.93%\n",
            "\n",
            "\n",
            "Iteration No: 26 ended. Search finished for the next optimal point.\n",
            "Time taken: 2876.6627\n",
            "Function value obtained: -0.9293\n",
            "Current minimum: -0.9321\n",
            "Iteration No: 27 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.0061615466838704e-05.\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 1.0061615284939763e-06.\n",
            "\n",
            "\n",
            "Accuracy: 92.47%\n",
            "\n",
            "\n",
            "Iteration No: 27 ended. Search finished for the next optimal point.\n",
            "Time taken: 4732.1137\n",
            "Function value obtained: -0.9247\n",
            "Current minimum: -0.9321\n",
            "Iteration No: 28 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\n",
            "\n",
            "Accuracy: 92.61%\n",
            "\n",
            "\n",
            "Iteration No: 28 ended. Search finished for the next optimal point.\n",
            "Time taken: 3220.7459\n",
            "Function value obtained: -0.9261\n",
            "Current minimum: -0.9321\n",
            "Iteration No: 29 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00017483937554061413.\n",
            "\n",
            "\n",
            "Accuracy: 92.55%\n",
            "\n",
            "\n",
            "Iteration No: 29 ended. Search finished for the next optimal point.\n",
            "Time taken: 6507.9529\n",
            "Function value obtained: -0.9255\n",
            "Current minimum: -0.9321\n",
            "Iteration No: 30 started. Searching for the next optimal point.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0006198943126946688.\n",
            "\n",
            "\n",
            "Accuracy: 89.50%\n",
            "\n",
            "\n",
            "Iteration No: 30 ended. Search finished for the next optimal point.\n",
            "Time taken: 470.8903\n",
            "Function value obtained: -0.8950\n",
            "Current minimum: -0.9321\n"
          ]
        }
      ],
      "source": [
        "bo_result = gp_minimize(func=objective_f,\n",
        "                            dimensions=search_space,\n",
        "                            n_calls=30,\n",
        "                            verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxXDicpT7rbN",
        "outputId": "b08cefe8-09ed-49c8-8052-d1c68db053c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters obtained via the Bayesian Optimization:\n",
            "\n",
            "nf_sp_1 = 48\n",
            "nf_sp_2 = 30\n",
            "nk_sp_l = 8\n",
            "nk_sp_r = 3\n",
            "mp_sp = 2\n",
            "dp_sp = 0.3208725109346078\n",
            "nf_tp_1 = 213\n",
            "nf_tp_2 = 70\n",
            "nk_tp_l = 6\n",
            "nk_tp_r = 8\n",
            "mp_tp_1 = 3\n",
            "mp_tp_2 = 1\n",
            "dp_tp = 0.29021674764792915\n",
            "dp_fc = 0.17477829885526042\n",
            "lr = 0.0073738292402841825\n"
          ]
        }
      ],
      "source": [
        "bo_parameters = {p.name: value for p, value in zip(search_space, bo_result.x)}\n",
        "print('Parameters obtained via the Bayesian Optimization:\\n')\n",
        "\n",
        "for i in bo_parameters:\n",
        "  print(i, '=', bo_parameters[i])\n",
        "\n",
        "# print('\\n')\n",
        "# plot_convergence(bo_result)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (14,10)\n",
        "plot_convergence(bo_result)\n",
        "plt.savefig('bayesian_optimization.svg', dpi=300, facecolor='white')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "9Qed5-lMu-uR",
        "outputId": "2c80cc15-2b13-41b4-ae06-1670082765ff"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1008x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-khCC16dgu2K"
      },
      "source": [
        "## 4 - Best model, training and testing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUkhIoN8Y32y"
      },
      "source": [
        "### 4.0 - Best model import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6SEkoJxU9CgE",
        "outputId": "b1c4ce70-1d99-4707-e349-377c03f3a2ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"custom_cnn\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 99, 40, 1)         0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 99, 40, 1)        4         \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 99, 40, 48)        1200      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 99, 40, 48)       192       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 99, 40, 48)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 49, 20, 48)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 49, 20, 48)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 49, 20, 30)        34590     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 49, 20, 30)       120       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 49, 20, 30)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 24, 10, 30)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 24, 10, 30)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 24, 10, 213)       306933    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 24, 10, 213)      852       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 24, 10, 213)       0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 8, 10, 213)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 8, 10, 213)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 10, 70)         715750    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 8, 10, 70)        280       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 8, 10, 70)         0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 8, 10, 70)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8, 10, 70)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 5600)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 5600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               1433856   \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 35)                8995      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,503,796\n",
            "Trainable params: 2,502,560\n",
            "Non-trainable params: 1,236\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGBA size=1703x292 at 0x7F7C9702E190>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "model = custom_cnn_simple(input_shape, *bo_result.x)\n",
        "model_name = 'custom_cnn_simple'\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "visualkeras.layered_view(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AOKfTzRgu2Y"
      },
      "source": [
        "### 4.1 - Model training\n",
        "At this point we can train the model for some epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "SUAN7oqp9dN3",
        "outputId": "1e3459de-b5cc-455d-b51b-7d5737679174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "2652/2652 [==============================] - 60s 22ms/step - loss: 1.1250 - sparse_categorical_accuracy: 0.6690 - val_loss: 0.5228 - val_sparse_categorical_accuracy: 0.8411 - lr: 0.0010\n",
            "Epoch 2/40\n",
            "2652/2652 [==============================] - 54s 20ms/step - loss: 0.5918 - sparse_categorical_accuracy: 0.8211 - val_loss: 0.4817 - val_sparse_categorical_accuracy: 0.8537 - lr: 0.0010\n",
            "Epoch 3/40\n",
            "2030/2652 [=====================>........] - ETA: 12s - loss: 0.5007 - sparse_categorical_accuracy: 0.8466"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-23e5dc68c5f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'trained_models/{model_name}.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epochs = 40\n",
        "\n",
        "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "reduce_LR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1)\n",
        "\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(f'trained_models/{model_name}.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "history = model.fit(\n",
        "                train_dataset,\n",
        "                epochs=num_epochs,\n",
        "                steps_per_epoch=train_steps,\n",
        "                validation_data=val_dataset,\n",
        "                validation_steps=val_steps,\n",
        "                callbacks=[early_stop_callback, model_checkpoint, reduce_LR], \n",
        "                verbose=1\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6xpCJ7Tgu2f"
      },
      "outputs": [],
      "source": [
        "print('Training history:')\n",
        "pd.DataFrame(history.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3Lq3SY4gu3J"
      },
      "outputs": [],
      "source": [
        "plot_utils.plot_history(history, columns=['loss', 'sparse_categorical_accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9R3FIblgu3O"
      },
      "source": [
        "Uncomment the cell below to save the weights of the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhUE4Zc6gu3P"
      },
      "outputs": [],
      "source": [
        "# model.save_weights(f'trained_models/{model_name}.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqXQhhpvgu5P"
      },
      "source": [
        "### 4.2 - Validation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9qSfMZlgu5U"
      },
      "outputs": [],
      "source": [
        "# get predictions for test set\n",
        "test_labels = reference_df_test['class']\n",
        "test_pred = model.predict(test_dataset, steps=test_steps, verbose=1)[:len(test_labels)].squeeze()\n",
        "\n",
        "# estimate class\n",
        "y_pred = np.argmax(test_pred, axis=1)\n",
        "\n",
        "# true labels\n",
        "y_true = reference_df_test['class'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jinyZOKNgu7V"
      },
      "source": [
        "Plot the confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHIhE3c3gu7e"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_pred, y_true)\n",
        "plot_utils.plot_confusion_matrix(cm, labels=commands, normalize=True, saveit=False, model_name='')\n",
        "# plt.savefig(f'figures/cm_{model_name}.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K19gHq1gu7z"
      },
      "source": [
        "Evaluate some metrics:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPE9Z35Xgu70"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
        "logloss  = log_loss(y_true, test_pred, labels=np.arange(35))\n",
        "cohen_k  = cohen_kappa_score(y_true, y_pred)\n",
        "\n",
        "# print('Accuracy:      {:.2f}%'.format(accuracy*100))\n",
        "# print('Error rate:    {:.2f}%'.format((1-accuracy)*100))\n",
        "# print('Cross-entropy: {:.4f}'.format(logloss))\n",
        "# print(\"Cohen's Kappa: {:.4f}\".format(cohen_k))\n",
        "\n",
        "def class_report(y_true, y_pred):\n",
        "    precision_macro,    recall_macro,    fscore_macro,    _ = precision_recall_fscore_support(y_true=y_true, y_pred=y_pred, average='macro')\n",
        "    precision_micro,    recall_micro,    fscore_micro,    _ = precision_recall_fscore_support(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    precision_weighted, recall_weighted, fscore_weighted, _ = precision_recall_fscore_support(y_true=y_true, y_pred=y_pred, average='weighted')\n",
        "    \n",
        "    df_report = pd.DataFrame(\n",
        "        {\n",
        "            'precision': [precision_macro, precision_micro, precision_weighted],\n",
        "            'recall': [recall_macro, recall_micro, recall_weighted],\n",
        "            'f1-score': [fscore_macro, fscore_micro, fscore_weighted]\n",
        "        }, \n",
        "        index=['macro', 'micro', 'weighted']\n",
        "    )\n",
        "    \n",
        "    return df_report\n",
        "\n",
        "cr = class_report(y_true, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaXtDPNwgu73"
      },
      "outputs": [],
      "source": [
        "# print('Testing of model %s with features %i...\\n' %(model_name, features_to_extract))\n",
        "weighted_metrics = cr.iloc[-1].tolist()\n",
        "\n",
        "df_metrics_simple = pd.DataFrame(\n",
        "    [weighted_metrics + [accuracy, logloss, cohen_k]], \n",
        "    columns = ['precision', 'recall', 'f1-score', 'accuracy', 'cross-entropy', 'Cohen-Kappa'], \n",
        ")\n",
        "\n",
        "display(df_metrics_simple.round(4))\n",
        "\n",
        "# Uncomment next lines to store the final metrics \n",
        "# if not os.path.exists(\"metrics\"):\n",
        "#   os.mkdir('metrics')\n",
        "#   \n",
        "# df_metrics.to_csv(f'metrics/metr_{model_name}_2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47NBCJ2yC_iA"
      },
      "outputs": [],
      "source": [
        "# tmp1 = pd.read_csv('metr_smallCnnModel_1.csv', index_col=0)\n",
        "# tmp2 = pd.read_csv('metr_smallCnnModel_2.csv', index_col=0)\n",
        "# \n",
        "# df_ = pd.concat([tmp1, tmp2], ignore_index=True, axis=0)\n",
        "# df_['Training'] = ['Without Delta', 'With Delta']\n",
        "# df_ = df_.set_index(['Training'])\n",
        "# df_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmZQ5DEzIvRE"
      },
      "source": [
        "## 5 - Best model modified, training and testing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5kfWpxDY7h9"
      },
      "source": [
        "### 5.0 - Modified model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vowWDe_wY-sS"
      },
      "outputs": [],
      "source": [
        "def custom_cnn(input_shape):\n",
        "    '''\n",
        "      4 cnn blocks, 2x (2, 2) pooling, 2x pooling in time\n",
        "    '''\n",
        "\n",
        "    model = tf.keras.models.Sequential(name='custom_cnn')\n",
        "\n",
        "    model.add(tf.keras.layers.Reshape(input_shape=input_shape, target_shape=(input_shape[0], input_shape[1], 1)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    filters_pool = [16, 32]\n",
        "\n",
        "    for num_filters in filters_pool:\n",
        "\n",
        "        model.add(tf.keras.layers.Conv2D(num_filters, kernel_size=(3, 3), padding='same'))\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "        model.add(tf.keras.layers.Conv2D(num_filters, kernel_size=(3, 3), padding='same'))\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "        model.add(tf.keras.layers.Conv2D(num_filters, kernel_size=(3, 3), padding='same'))\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "    filters_pool_in_time = [64, 128]\n",
        "\n",
        "    for p, num_filters in zip([2, 4], filters_pool_in_time):\n",
        "\n",
        "        model.add(tf.keras.layers.Conv2D(num_filters, kernel_size=(3, 3), padding='same'))\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(p, 1)))\n",
        "        model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(512, name='features512'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation('relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.4))\n",
        "    model.add(tf.keras.layers.Dense(256, name='features256'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation('relu'))\n",
        "    model.add(tf.keras.layers.Dense(35, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "model = custom_cnn(input_shape)\n",
        "model_name = 'custom_cnn'\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "visualkeras.layered_view(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NoCqC6nZdJY"
      },
      "source": [
        "### 5.1 - Model training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyek5P-7ZVgk"
      },
      "outputs": [],
      "source": [
        "num_epochs = 40\n",
        "\n",
        "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "reduce_LR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1)\n",
        "\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(f'trained_models/{model_name}.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "history = model.fit(\n",
        "                train_dataset,\n",
        "                epochs=num_epochs,\n",
        "                steps_per_epoch=train_steps,\n",
        "                validation_data=val_dataset,\n",
        "                validation_steps=val_steps,\n",
        "                callbacks=[early_stop_callback, model_checkpoint, reduce_LR], \n",
        "                verbose=1\n",
        "                )\n",
        "\n",
        "print('Training history:')\n",
        "pd.DataFrame(history.history)\n",
        "\n",
        "plot_utils.plot_history(history, columns=['loss', 'sparse_categorical_accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlOWhs9AZxkz"
      },
      "source": [
        "Uncomment the cell below to save the weights of the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1zQrPBKZU09"
      },
      "outputs": [],
      "source": [
        "# model.save_weights(f'trained_models/{model_name}.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asl2lKDFZ06t"
      },
      "source": [
        "### 5.2 - Validation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JizV87dWZUO_"
      },
      "outputs": [],
      "source": [
        "# get predictions for test set\n",
        "test_labels = reference_df_test['class']\n",
        "test_pred = model.predict(test_dataset, steps=test_steps, verbose=1)[:len(test_labels)].squeeze()\n",
        "\n",
        "# estimate class\n",
        "y_pred = np.argmax(test_pred, axis=1)\n",
        "\n",
        "# true labels\n",
        "y_true = reference_df_test['class'].tolist()\n",
        "\n",
        "# plot cm\n",
        "cm = confusion_matrix(y_pred, y_true)\n",
        "plot_utils.plot_confusion_matrix(cm, labels=commands, normalize=True, saveit=False, model_name='')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVBjahZBaK3s"
      },
      "outputs": [],
      "source": [
        "# get metrics and display them \n",
        "accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
        "logloss  = log_loss(y_true, test_pred, labels=np.arange(35))\n",
        "cohen_k  = cohen_kappa_score(y_true, y_pred)\n",
        "\n",
        "# print('Accuracy:      {:.2f}%'.format(accuracy*100))\n",
        "# print('Error rate:    {:.2f}%'.format((1-accuracy)*100))\n",
        "# print('Cross-entropy: {:.4f}'.format(logloss))\n",
        "# print(\"Cohen's Kappa: {:.4f}\".format(cohen_k))\n",
        "\n",
        "cr = class_report(y_true, y_pred)\n",
        "weighted_metrics = cr.iloc[-1].tolist()\n",
        "\n",
        "df_metrics_modified = pd.DataFrame(\n",
        "    [weighted_metrics + [accuracy, logloss, cohen_k]], \n",
        "    columns = ['precision', 'recall', 'f1-score', 'accuracy', 'cross-entropy', 'Cohen-Kappa'], \n",
        ")\n",
        "\n",
        "display(df_metrics_modified.round(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PPkbPB6aZWw"
      },
      "source": [
        "# Feature Comparison\n",
        "We use the last model to compare performance using different audio features as input. Recall that in the function `preprocessing_utils.load_and_preprocess_data` we defined the following features:\n",
        "\n",
        "```python\n",
        "features_to_input = { # input shapes\n",
        "    1 : (99, 13),     # MFCC features with delta\n",
        "    2 : (99, 40),     # log Mel-filterbank energy features\n",
        "    3 : (98, 257),    # spectrogram\n",
        "    4 : (49, 39),     # Discrete Wavelet Transform + MFCC features\n",
        "    5 : (99, 13)      # MFCC features no delta\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT9gC2KibFQ5"
      },
      "source": [
        "## 6 - FC, training and testing loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70wQsOBebPB6"
      },
      "outputs": [],
      "source": [
        "def training_and_testing(feature_selected, df_store=None, noise_red=0.5):\n",
        "  # remove cache files\n",
        "  remove_file_starting_with('train')\n",
        "  remove_file_starting_with('val')\n",
        "  remove_file_starting_with('test')\n",
        "\n",
        "  # create datasets\n",
        "  train_dataset, train_steps = create_dataset(\n",
        "      reference_df_train, \n",
        "      apply_background_noise=apply_bn,\n",
        "      noise_reduction=noise_red,\n",
        "      features=feature_selected,\n",
        "      cache_file='train_cache',\n",
        "      shuffle=True,\n",
        "      batch_size=batch_size\n",
        "  )\n",
        "\n",
        "  val_dataset, val_steps = create_dataset(\n",
        "      reference_df_val,\n",
        "      apply_background_noise=apply_bn,\n",
        "      noise_reduction=noise_red,\n",
        "      features=feature_selected,\n",
        "      cache_file='val_cache',\n",
        "      shuffle=True,\n",
        "      batch_size=batch_size\n",
        "  )\n",
        "\n",
        "  test_dataset, test_steps = create_dataset(\n",
        "      reference_df_test,\n",
        "      apply_background_noise=False, \n",
        "      features=feature_selected,\n",
        "      cache_file='test_cache',\n",
        "      shuffle=False,\n",
        "      batch_size=batch_size\n",
        "  )\n",
        "\n",
        "  # input shape\n",
        "  input_shape = features_to_input[feature_selected]\n",
        "\n",
        "  # model\n",
        "  model = custom_cnn(input_shape)\n",
        "  model_name = 'custom_cnn'\n",
        "\n",
        "  model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
        "\n",
        "  # training\n",
        "  print('Start training... ')\n",
        "  num_epochs = 40\n",
        "\n",
        "  early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "  reduce_LR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1)\n",
        "\n",
        "  model_checkpoint = tf.keras.callbacks.ModelCheckpoint(f'trained_models/{model_name}.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "  history = model.fit(\n",
        "                  train_dataset,\n",
        "                  epochs=num_epochs,\n",
        "                  steps_per_epoch=train_steps,\n",
        "                  validation_data=val_dataset,\n",
        "                  validation_steps=val_steps,\n",
        "                  callbacks=[early_stop_callback, model_checkpoint, reduce_LR], \n",
        "                  verbose=0\n",
        "                  )\n",
        "  \n",
        "  print('Training completed!')\n",
        "\n",
        "  # testing\n",
        "  test_labels = reference_df_test['class']\n",
        "  test_pred = model.predict(test_dataset, steps=test_steps, verbose=1)[:len(test_labels)].squeeze()\n",
        "\n",
        "  y_pred = np.argmax(test_pred, axis=1)\n",
        "  y_true = reference_df_test['class'].tolist()\n",
        "\n",
        "  accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
        "  logloss  = log_loss(y_true, test_pred, labels=np.arange(35))\n",
        "  cohen_k  = cohen_kappa_score(y_true, y_pred)\n",
        "\n",
        "  cr = class_report(y_true, y_pred)\n",
        "  weighted_metrics = cr.iloc[-1].tolist()\n",
        "\n",
        "  df_metrics = pd.DataFrame(\n",
        "      [weighted_metrics + [accuracy, logloss, cohen_k]], \n",
        "      columns = ['precision', 'recall', 'f1-score', 'accuracy', 'cross-entropy', 'Cohen-Kappa'], \n",
        "  )\n",
        "\n",
        "  # store results\n",
        "  if df_store is not None:\n",
        "    df_return = pd.concat([df_store, df_metrics])\n",
        "  else:\n",
        "    df_return = df_metrics\n",
        "\n",
        "  return df_return\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzdaIifTfc-l"
      },
      "source": [
        "Let's run the above function for all features and store the resulting metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYlEL78PehCL"
      },
      "outputs": [],
      "source": [
        "for feat in np.arange(1, 6):\n",
        "\n",
        "  if feat==1:\n",
        "    df_output = training_and_testing(feat)\n",
        "\n",
        "  else:\n",
        "    df_output = training_and_testing(feat, df_output)\n",
        "\n",
        "display(df_output.round(4))\n",
        "\n",
        "if not os.path.exists(\"metrics\"):\n",
        "  os.mkdir('metrics')\n",
        "\n",
        "df_output.to_csv(f'metrics/metr_feat_comparison.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmfIfiwvhWKi"
      },
      "source": [
        "# Extra: background noise effect \n",
        "It is also possible to study the effect of adding background noise when training the best CNN model. To do this, we train the model using different noise levels on the train and validation sets, while the test set is kept noise-free for comparison purposes. In this procedure we use the best features found in the previous step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOpw-JpuiGdn"
      },
      "outputs": [],
      "source": [
        "noise_red_levels = [0, 0.25, 0.5, 0.75, 1]\n",
        "features_to_use = 2\n",
        "\n",
        "for nr in noise_red_levels:\n",
        "\n",
        "  if nr==1:\n",
        "    df_output_noise = training_and_testing(features_to_use, noise_red=nr)\n",
        "\n",
        "  else:\n",
        "    df_output_noise = training_and_testing(features_to_use, df_store = df_output, noise_red=nr)\n",
        "\n",
        "# results\n",
        "display(df_output_noise.round(4))\n",
        "\n",
        "if not os.path.exists(\"metrics\"):\n",
        "  os.mkdir('metrics')\n",
        "\n",
        "df_output_noise.to_csv(f'metrics/metr_noise_effect.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqEwef54gu74"
      },
      "source": [
        "# References\n",
        "**[Sainath15]** <br>\n",
        " Tara N. Sainath, Carolina Parada, _Convolutional Neural Networks for Small-footprint Keyword Spotting_, INTERSPEECH, Dresden, Germany, September 2015.\n",
        "\n",
        "**[Warden18]** <br>\n",
        " Pete Warden, _Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition_, arXiv:1804.03209, April 2018. \n",
        " \n",
        "**[Lyons14]** <br>\n",
        " James Lyons et al. (2020, January 14). jameslyons/python_speech_features: release v0.6.1 (Version 0.6.1). Zenodo.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "DL_Keras",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "51b7e6a6adb8df7affebc30c4882993a05eedb7d3f8cde5d27ca88ae74048761"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}